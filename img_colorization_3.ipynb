{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled5.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"0j8uUzM8_dho","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","!mkdir -p full\n","os.chdir('full')\n","!mkdir -p Train\n","!mkdir -p Test\n","!mkdir -p Result"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sZNOj1Ys_4pj","colab_type":"code","outputId":"3c406027-2c4d-4676-fdaf-e57775c6afc3","executionInfo":{"status":"ok","timestamp":1542834973047,"user_tz":-330,"elapsed":6792,"user":{"displayName":"Yajurv Bhatia","photoUrl":"https://lh6.googleusercontent.com/-FW1EAxkHFbg/AAAAAAAAAAI/AAAAAAAATO8/kpd9nTpj1WQ/s64/photo.jpg","userId":"05670612901100748749"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import os\n","!mkdir -p Train\n","!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Result\tTest  Train\n"],"name":"stdout"}]},{"metadata":{"id":"4wNhs2CU_u9f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a9507e44-d068-4c4c-b3d7-b90130d7fba7","executionInfo":{"status":"ok","timestamp":1542845262982,"user_tz":-330,"elapsed":3009,"user":{"displayName":"Yajurv Bhatia","photoUrl":"https://lh6.googleusercontent.com/-FW1EAxkHFbg/AAAAAAAAAAI/AAAAAAAATO8/kpd9nTpj1WQ/s64/photo.jpg","userId":"05670612901100748749"}}},"cell_type":"code","source":["import keras\n","from keras.applications.inception_resnet_v2 import InceptionResNetV2\n","from keras.preprocessing import image\n","from keras.engine import Layer\n","from keras.applications.inception_resnet_v2 import preprocess_input\n","from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n","from keras.layers import Activation, Dense, Dropout, Flatten\n","from keras.layers.normalization import BatchNormalization\n","from keras.callbacks import TensorBoard \n","from keras.models import Sequential, Model\n","from keras.layers.core import RepeatVector, Permute\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n","from skimage.transform import resize\n","from skimage.io import imsave\n","import numpy as np\n","import os\n","import random\n","import tensorflow as tf"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"2h7iixJq_0wB","colab_type":"code","outputId":"a266c0e3-27e7-42fb-8080-1312da08630e","executionInfo":{"status":"ok","timestamp":1542845697508,"user_tz":-330,"elapsed":58141,"user":{"displayName":"Yajurv Bhatia","photoUrl":"https://lh6.googleusercontent.com/-FW1EAxkHFbg/AAAAAAAAAAI/AAAAAAAATO8/kpd9nTpj1WQ/s64/photo.jpg","userId":"05670612901100748749"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["# Get images\n","X = []\n","for filename in os.listdir('Train/'):\n","    X.append(img_to_array(load_img('Train/'+filename)))\n","X = np.array(X, dtype=float)\n","Xtrain = 1.0/255*X\n","\n","\n","#Load weights\n","inception = InceptionResNetV2(weights='imagenet', include_top=True)\n","inception.graph = tf.get_default_graph()\n","embed_input = Input(shape=(1000,))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n","225214464/225209952 [==============================] - 14s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"smYRtdpE__oY","colab_type":"code","colab":{}},"cell_type":"code","source":["#Encoder\n","encoder_input = Input(shape=(256, 256, 1,))\n","encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n","encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n","encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n","encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n","encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n","encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n","encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n","encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n","\n","#Fusion\n","fusion_output = RepeatVector(32 * 32)(embed_input) \n","fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n","fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n","fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n","\n","#Decoder\n","decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n","decoder_output = UpSampling2D((2, 2))(decoder_output)\n","decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n","decoder_output = UpSampling2D((2, 2))(decoder_output)\n","decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n","decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n","decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n","decoder_output = UpSampling2D((2, 2))(decoder_output)\n","\n","model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cKdslRmCADon","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2397},"outputId":"a35d87e0-61d4-455a-d928-dc62812bb997","executionInfo":{"status":"ok","timestamp":1542853618340,"user_tz":-330,"elapsed":7893403,"user":{"displayName":"Yajurv Bhatia","photoUrl":"https://lh6.googleusercontent.com/-FW1EAxkHFbg/AAAAAAAAAAI/AAAAAAAATO8/kpd9nTpj1WQ/s64/photo.jpg","userId":"05670612901100748749"}}},"cell_type":"code","source":["def create_inception_embedding(grayscaled_rgb):\n","    grayscaled_rgb_resized = []\n","    for i in grayscaled_rgb:\n","        i = resize(i, (299, 299, 3), mode='constant')\n","        grayscaled_rgb_resized.append(i)\n","    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n","    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n","    with inception.graph.as_default():\n","        embed = inception.predict(grayscaled_rgb_resized)\n","    return embed\n","\n","# Image transformer\n","datagen = ImageDataGenerator(\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        rotation_range=20,\n","        horizontal_flip=True)\n","\n","# Generate training data\n","batch_size = 50\n","\n","def image_a_b_gen(batch_size):\n","    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n","        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n","        embed = create_inception_embedding(grayscaled_rgb)\n","        lab_batch = rgb2lab(batch)\n","        X_batch = lab_batch[:,:,:,0]\n","        X_batch = X_batch.reshape(X_batch.shape+(1,))\n","        Y_batch = lab_batch[:,:,:,1:] / 128\n","        yield ([X_batch, create_inception_embedding(grayscaled_rgb)], Y_batch)\n","\n","\n","# Train model     \n","tensorboard = TensorBoard(log_dir=\"output/sixth_run\")\n","model.compile(optimizer='rmsprop', loss='mse')\n","model.fit_generator(image_a_b_gen(batch_size), epochs=70, steps_per_epoch=16)\n","model.save('finalmodel.h5')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1/70\n","16/16 [==============================] - 132s 8s/step - loss: 0.2151\n","Epoch 2/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0099\n","Epoch 3/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0098\n","Epoch 4/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0098\n","Epoch 5/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 6/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 7/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0100\n","Epoch 8/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 9/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 10/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 11/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 12/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 13/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0104\n","Epoch 14/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0099\n","Epoch 15/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0102\n","Epoch 16/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0097\n","Epoch 17/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0097\n","Epoch 18/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 19/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 20/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0098\n","Epoch 21/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 22/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 23/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 24/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 25/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 26/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 27/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 28/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 29/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0107\n","Epoch 30/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0098\n","Epoch 31/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 32/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 33/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 34/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0098\n","Epoch 35/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0099\n","Epoch 36/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 37/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0099\n","Epoch 38/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0097\n","Epoch 39/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0097\n","Epoch 40/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 41/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0100\n","Epoch 42/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0097\n","Epoch 43/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0097\n","Epoch 44/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 45/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0097\n","Epoch 46/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 47/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0098\n","Epoch 48/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 49/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 50/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 51/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0096\n","Epoch 52/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 53/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 54/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 55/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0096\n","Epoch 56/70\n","16/16 [==============================] - 111s 7s/step - loss: 0.0096\n","Epoch 57/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0097\n","Epoch 58/70\n","16/16 [==============================] - 113s 7s/step - loss: 0.0096\n","Epoch 59/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0096\n","Epoch 60/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0095\n","Epoch 61/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0096\n","Epoch 62/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0096\n","Epoch 63/70\n","16/16 [==============================] - 111s 7s/step - loss: 0.0096\n","Epoch 64/70\n","16/16 [==============================] - 111s 7s/step - loss: 0.0096\n","Epoch 65/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0096\n","Epoch 66/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0096\n","Epoch 67/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0096\n","Epoch 68/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0095\n","Epoch 69/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0096\n","Epoch 70/70\n","16/16 [==============================] - 112s 7s/step - loss: 0.0096\n"],"name":"stdout"}]},{"metadata":{"id":"uRlZLy5wwdN0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":183},"outputId":"f1d0ffbe-8827-48f9-ca49-29c610073463","executionInfo":{"status":"error","timestamp":1542845523425,"user_tz":-330,"elapsed":10959,"user":{"displayName":"Yajurv Bhatia","photoUrl":"https://lh6.googleusercontent.com/-FW1EAxkHFbg/AAAAAAAAAAI/AAAAAAAATO8/kpd9nTpj1WQ/s64/photo.jpg","userId":"05670612901100748749"}}},"cell_type":"code","source":["model.save('finalmodel.h5')"],"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-a1b9256778aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finalmodel.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"metadata":{"id":"d9BEWlC8AE-c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"e761a47e-306e-4956-e7f4-8999f9fb8982","executionInfo":{"status":"ok","timestamp":1542854061002,"user_tz":-330,"elapsed":17806,"user":{"displayName":"Yajurv Bhatia","photoUrl":"https://lh6.googleusercontent.com/-FW1EAxkHFbg/AAAAAAAAAAI/AAAAAAAATO8/kpd9nTpj1WQ/s64/photo.jpg","userId":"05670612901100748749"}}},"cell_type":"code","source":["# Load model\n","\n","from keras.models import load_model\n","new_model=load_model('finalmodel.h5')\n","\n","color_me = []\n","for filename in os.listdir('Test/'):\n","    color_me.append(img_to_array(load_img('Test/'+filename)))\n","color_me = np.array(color_me, dtype=float)\n","gray_me = gray2rgb(rgb2gray(1.0/255*color_me))\n","color_me_embed = create_inception_embedding(gray_me)\n","color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n","color_me = color_me.reshape(color_me.shape+(1,))\n","\n","\n","# Test model\n","output = new_model.predict([color_me, color_me_embed])\n","output = output * 128\n","\n","# Output colorizations\n","for i in range(len(output)):\n","    cur = np.zeros((256, 256, 3))\n","    cur[:,:,0] = color_me[i][:,:,0]\n","    cur[:,:,1:] = output[i]\n","    imsave(\"Result/semmedimg_\"+str(i)+\".png\", lab2rgb(cur))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n","  .format(dtypeobj_in, dtypeobj_out))\n"],"name":"stderr"}]}]}